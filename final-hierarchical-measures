1. Summarization
summary-out-comb-top200-laura-cand-train-run
map                       all    0.0108
Rprec                     all    0.0084
recip_rank                all    0.0234

2. HAC with wordnet similarity
hacsim-comb-top200-laura-cand-train-run
map                       all    0.0029
Rprec                     all    0.0016
recip_rank                all    0.0054

3. HAC with word2vec vectors
hacwv-comb-top200-laura-cand-train-run
map                       all    0.0027
Rprec                     all    0.0020
recip_rank                all    0.0059

4. KMeans with word2vec vectors
kmwv-comb-top200-laura-cand-train-run
map                       all    0.0034
Rprec                     all    0.0022
recip_rank                all    0.0073

5. LDA topic model with wordnet synonyms
topic-model-expanded-sec-train-run
map                       all    0.0073
Rprec                     all    0.0030
recip_rank                all    0.0117

6. LDA topic model
topic-model-train-run
map                       all    0.0060
Rprec                     all    0.0025
recip_rank                all    0.0121

7. Datamuse + Concept net + BM25
query-expansion-data-muse-and-CN-BM25-run
map                       all    0.0168
Rprec                     all    0.0109
recip_rank                all    0.0225

9. Weighted PageRank with Common Entities
map                       all    0.0072
Rprec                     all    0.0044
recip_rank                all    0.0146

10. Weighted PageRank with Common Words
map                       all    0.0083
Rprec                     all    0.0054
recip_rank                all    0.0167

------ Candidate sets ----------


8. Candidate Set Generation using Query Expansion with entities from DBPedia
MAP : 0.0567
Rprec : 0.0985
recip_rank : 0.3478

11. BM25+(BM25+KNN-INC)+(BM25+KNN-EXT)
map                       all    0.0877
Rprec                     all    0.1449
recip_rank                all    0.4501

12. LM-DS+(LM-DS+KNN-INC)+(LM-DS+KNN-EXT)
map                       all    0.0933
Rprec                     all    0.1520
recip_rank                all    0.4349

13. LM-JM+(LM-JM+KNN-INC)+(LM-JM+KNN-EXT)
map                       all    0.0699
Rprec                     all    0.1202
recip_rank                all    0.3397

11. ALL
map                       all    0.0988
Rprec                     all    0.1578
recip_rank                all    0.4996

12. Shubham cand + laura combined using Rlib
map                   	all	0.1355
Rprec                 	all	0.1947
recip_rank            	all	0.6721

13. Datamuse + BM25
map                     all     0.0183
Rprec                   all     0.0332
recip_rank              all     0.0792

14. Added ConceptNet with DataMuse + BM25
map                     all     0.0586
Rprec                   all     0.0999
recip_rank              all     0.2940

15. DataMuse + BM25 + ConceptNet for hierarchical sections
map                     all     0.0206
Rprec                   all     0.0134
recip_rank              all     0.0275
